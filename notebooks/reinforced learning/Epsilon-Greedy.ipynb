{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Epsilon-Greedy simple implementation:\n",
    "\n",
    "This code initializes the variables needed for the algorithm, loops through a specified number of plays, and performs the Epsilon-Greedy action selection for each play. \n",
    "\n",
    "It then simulates a reward for the chosen arm and updates the Q-value and N-value for that arm based on the reward. Finally, it prints the final Q-values after all plays have been completed.\n",
    "\n",
    "    Initialize a list of N arms, each with an unknown reward probability.\n",
    "\n",
    "    Set a value for epsilon, which represents the probability of exploration. For example, if epsilon = 0.1, then 10% of the time we will explore a random arm, and 90% of the time we will choose the arm with the highest estimated reward.\n",
    "\n",
    "    For each round or iteration:\n",
    "    a. With probability epsilon, choose a random arm to explore.\n",
    "    b. Otherwise, choose the arm with the highest estimated reward.\n",
    "    c. Observe the reward from the chosen arm.\n",
    "    d. Update the estimated reward for the chosen arm based on the observed reward.\n",
    "\n",
    "    Repeat step 3 for a fixed number of rounds or until convergence.\n",
    "\n",
    "Here are some variables you will need to use:\n",
    "\n",
    "    N: the number of arms\n",
    "    epsilon: the probability of exploration\n",
    "    Q: a list of length N to store the estimated reward for each arm\n",
    "    N_pulls: a list of length N to store the number of times each arm has been pulled\n",
    "    a function to calculate the average reward for each arm\n",
    "\n",
    "To implement step 3d, you will need to update the estimated reward for the chosen arm using the following formula:\n",
    "Q[a] = Q[a] + (r - Q[a]) / N_pulls[a]\n",
    "\n",
    "where a is the index of the chosen arm, r is the observed reward, and N_pulls[a] is the number of times the arm has been pulled before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Initialize variables\n",
    "num_arms = 10\n",
    "epsilon = 0.1\n",
    "q_values = [0] * num_arms\n",
    "n_values = [0] * num_arms\n",
    "\n",
    "# Loop for each play\n",
    "for play in range(1000):\n",
    "\n",
    "    # Epsilon-Greedy action selection\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        # Choose a random arm\n",
    "        arm = random.randint(0, num_arms-1)\n",
    "    else:\n",
    "        # Choose the arm with the highest Q-value\n",
    "        arm = q_values.index(max(q_values))\n",
    "\n",
    "    # Simulate reward for chosen arm\n",
    "    reward = random.gauss(0, 1)\n",
    "\n",
    "    # Update Q-value and N-value for chosen arm\n",
    "    n_values[arm] += 1\n",
    "    q_values[arm] += (1/n_values[arm]) * (reward - q_values[arm])\n",
    "\n",
    "# Print final Q-values\n",
    "print(q_values)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
